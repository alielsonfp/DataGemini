{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alielsonfp/DataGemini/blob/main/datagemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "84SKunEci9hX"
      },
      "outputs": [],
      "source": [
        "# Instalação da biblioteca google-generativeai (comente se já estiver instalada)\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iOaCHuzGYf7a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import google.generativeai as genai\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Credenciais da API\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get(\"SECRET_KEY\")\n",
        "genai.configure(api_key= api_key)\n",
        "\n",
        "#  Configurando o modelo generativo que será utilizado\n",
        "instruction = (\"Você é um analista de dados fornecera informações detalhadas sobre datasets de forma clara e objetiva\"\n",
        "               \"quando for pedido para gerar graficos não adicionara nenhum comentario ao codigo, não adicionar ```` python no começo do codigo nem ´´´´´ no final, apenas fornecera o codigo pronto para ser executado\"\n",
        "               \"A prioridade é sempre utilizar a biblioteca  plotly.graph_objs para gerar graficos quando for possível\"\n",
        ")\n",
        "model = genai.GenerativeModel('models/gemini-1.5-pro-latest', system_instruction=instruction)"
      ],
      "metadata": {
        "id": "R6BvNLjiBFlm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lendo o arquivo CSV, coloque aqui o seu\n",
        "df = pd.read_csv('/content/10 maiores empresas.csv')\n",
        "nome_arquivo = os.path.basename('/content/10 maiores empresas.csv')\n",
        "df_texto = df.to_string()\n"
      ],
      "metadata": {
        "id": "C3_hTwXcTRA5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "cFPV1TOkagls",
        "outputId": "15d0f2cd-f2d9-4f70-c0d8-8a4abe269dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olá! Eu sou o DataGemini e estou aqui para te ajudar a entender mais sobre o data set 10 maiores empresas.csv.\n",
            "Se quiser gerar gráficos, comece o prompT com 'gerar grafico' + as especificações como por exemplo tipo de grafico.\n",
            "Se quiser sair, basta digitar 'encerrar'. :)\n"
          ]
        }
      ],
      "source": [
        "#Iniciando chat\n",
        "chat = model.start_chat(history=[])\n",
        "chat.send_message(\"Essa é a base de dados que você ira analisar \" + df_texto)\n",
        "\n",
        "print(f\"Olá! Eu sou o DataGemini e estou aqui para te ajudar a entender mais sobre o data set {nome_arquivo}.\"\n",
        "\"\\nSe quiser gerar gráficos, comece o prompT com 'gerar grafico' + as especificações como por exemplo tipo de grafico.\"\n",
        "\"\\nSe quiser sair, basta digitar 'encerrar'. :)\"\n",
        ")\n",
        "\n",
        "while True:\n",
        "    # Aguarda a entrada do usuário\n",
        "    user_input = input(\"Você: \")\n",
        "\n",
        "    # Verifica se o usuário deseja encerrar o chat\n",
        "    if user_input.lower() == 'encerrar':\n",
        "        print(\"Chat encerrado.\")\n",
        "        break\n",
        "\n",
        "    # Se o usuário solicitar um gráfico\n",
        "    if 'gerar grafico' in user_input.lower():\n",
        "        prompt_with_data = f\"{user_input} {df_texto}\"\n",
        "        response = model.generate_content(prompt_with_data)\n",
        "        codigo = response.text\n",
        "        exec(codigo)\n",
        "        continue\n",
        "\n",
        "    # Obtém a resposta do chatbot com base na entrada do usuário\n",
        "    response = chat.send_message(user_input)\n",
        "\n",
        "    # Extrai o texto da resposta\n",
        "    response_text = response._result.candidates[0].content.parts[0].text\n",
        "\n",
        "    # Exibe a resposta do chatbot\n",
        "    print(\"DataGemini:\", response_text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkt8zwb4BcaVIotip3Gcck",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}